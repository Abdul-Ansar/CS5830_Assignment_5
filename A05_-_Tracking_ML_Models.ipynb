{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4811a7-6b86-42ee-84bf-d97874594bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from mlflow import log_metric, log_param\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3e735f0-36c2-4c03-aa3c-840be41d8671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/21 09:51:32 INFO mlflow.tracking.fluent: Experiment with name 'MNIST Models' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/452122521761317738', creation_time=1713673292188, experiment_id='452122521761317738', last_update_time=1713673292188, lifecycle_stage='active', name='MNIST Models', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8000\")\n",
    "experiment_name = \"MNIST Models\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6508aa-1d49-48f5-a5a7-28cb98cded84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 09:51:32.598508: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 09:51:34.209791: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\"\"\"### Load & Prepare MNIST Dataset\"\"\"\n",
    "from tensorflow import keras\n",
    "(X_train, Y_train), (X_test, Y_test) = keras.datasets.mnist.load_data()\n",
    "num_classes = 10\n",
    "x_train = X_train.reshape(60000, 784)\n",
    "x_test = X_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float16') / 255\n",
    "x_test = x_test.astype('float16') / 255\n",
    "y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(Y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f8cdc5-2900-47ac-b169-e26fa58ebc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8879122-b294-41e4-8883-66a666f8632f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 09:51:36.346086: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-04-21 09:51:36.346978: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2251] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.5774 - loss: 1.5324 - val_accuracy: 0.8964 - val_loss: 0.4386\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.3826 - val_accuracy: 0.9191 - val_loss: 0.2843\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9264 - loss: 0.2662 - val_accuracy: 0.9312 - val_loss: 0.2374\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.2197 - val_accuracy: 0.9398 - val_loss: 0.2099\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 2ms/step - accuracy: 0.9459 - loss: 0.1938 - val_accuracy: 0.9432 - val_loss: 0.1943\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9499 - loss: 0.1758 - val_accuracy: 0.9455 - val_loss: 0.1860\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.1599 - val_accuracy: 0.9490 - val_loss: 0.1717\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9567 - loss: 0.1484 - val_accuracy: 0.9501 - val_loss: 0.1691\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9596 - loss: 0.1409 - val_accuracy: 0.9498 - val_loss: 0.1677\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9619 - loss: 0.1319 - val_accuracy: 0.9510 - val_loss: 0.1649\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Simple neural network with two hidden layers\n",
    "with mlflow.start_run(run_name=\"Model 1\"):\n",
    "    log_param(\"hidden_layers\", [20,20])\n",
    "    log_param(\"learning_rate\", 0.001)\n",
    "    log_param(\"optimizer\", \"Adam\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(20, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b250ef82-3cde-4b0d-9841-daa0586af194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.8179 - loss: 0.6883 - val_accuracy: 0.9444 - val_loss: 0.1916\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9477 - loss: 0.1763 - val_accuracy: 0.9588 - val_loss: 0.1286\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9674 - loss: 0.1084 - val_accuracy: 0.9673 - val_loss: 0.1046\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9773 - loss: 0.0784 - val_accuracy: 0.9659 - val_loss: 0.1076\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0586 - val_accuracy: 0.9744 - val_loss: 0.0801\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0396 - val_accuracy: 0.9786 - val_loss: 0.0675\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0314 - val_accuracy: 0.9804 - val_loss: 0.0686\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0237 - val_accuracy: 0.9793 - val_loss: 0.0681\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9952 - loss: 0.0179 - val_accuracy: 0.9803 - val_loss: 0.0669\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0136 - val_accuracy: 0.9779 - val_loss: 0.0722\n"
     ]
    }
   ],
   "source": [
    "# Model 2: Bigger Model\n",
    "with mlflow.start_run(run_name=\"Model 2\"):\n",
    "    log_param(\"hidden_layers\", [256,128])\n",
    "    log_param(\"learning_rate\", 0.001)\n",
    "    log_param(\"optimizer\", \"Adam\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(128, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d2ffc9-9cc3-4a66-bcd1-22afd01b375c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.5612 - loss: 2.4032 - val_accuracy: 0.7766 - val_loss: 1.3754\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7612 - loss: 1.3375 - val_accuracy: 0.7799 - val_loss: 1.1977\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.7814 - loss: 1.2026 - val_accuracy: 0.7567 - val_loss: 1.1696\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 1.1385 - val_accuracy: 0.7849 - val_loss: 1.0807\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.7869 - loss: 1.1015 - val_accuracy: 0.8189 - val_loss: 1.0393\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.7941 - loss: 1.0704 - val_accuracy: 0.7725 - val_loss: 1.0699\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.7987 - loss: 1.0392 - val_accuracy: 0.8240 - val_loss: 0.9770\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 5ms/step - accuracy: 0.8008 - loss: 1.0277 - val_accuracy: 0.8102 - val_loss: 0.9837\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8033 - loss: 1.0088 - val_accuracy: 0.8367 - val_loss: 0.9412\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.9859 - val_accuracy: 0.7971 - val_loss: 0.9745\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8076 - loss: 0.9742 - val_accuracy: 0.8356 - val_loss: 0.9266\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.9703 - val_accuracy: 0.8323 - val_loss: 0.9028\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8142 - loss: 0.9468 - val_accuracy: 0.8104 - val_loss: 0.9406\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.8175 - loss: 0.9357 - val_accuracy: 0.8162 - val_loss: 0.9242\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8161 - loss: 0.9314 - val_accuracy: 0.8225 - val_loss: 0.9089\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8167 - loss: 0.9258 - val_accuracy: 0.8317 - val_loss: 0.8718\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8259 - loss: 0.9029 - val_accuracy: 0.8272 - val_loss: 0.8724\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8273 - loss: 0.8945 - val_accuracy: 0.8308 - val_loss: 0.8735\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8339 - loss: 0.8856 - val_accuracy: 0.8176 - val_loss: 0.9264\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8327 - loss: 0.8809 - val_accuracy: 0.8548 - val_loss: 0.8377\n"
     ]
    }
   ],
   "source": [
    "from keras import regularizers\n",
    "# Model 3: L2 Regularization\n",
    "with mlflow.start_run(run_name=\"Model 3\"):\n",
    "    log_param(\"hidden_layers\", [256,128])\n",
    "    log_param(\"learning_rate\", 0.001)\n",
    "    log_param(\"optimizer\", \"Adam\")\n",
    "    log_param(\"regularization\", \"L2\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='sigmoid', input_shape=(784,), kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dense(128, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f6ebbdd-b749-4bf3-b78c-237733c04dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.6555 - loss: 1.0640 - val_accuracy: 0.9257 - val_loss: 0.2482\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9035 - loss: 0.3271 - val_accuracy: 0.9465 - val_loss: 0.1732\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9277 - loss: 0.2461 - val_accuracy: 0.9564 - val_loss: 0.1402\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9414 - loss: 0.1994 - val_accuracy: 0.9638 - val_loss: 0.1171\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.1721 - val_accuracy: 0.9682 - val_loss: 0.1074\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9540 - loss: 0.1532 - val_accuracy: 0.9716 - val_loss: 0.0924\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9582 - loss: 0.1402 - val_accuracy: 0.9723 - val_loss: 0.0873\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9622 - loss: 0.1292 - val_accuracy: 0.9737 - val_loss: 0.0863\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9640 - loss: 0.1224 - val_accuracy: 0.9740 - val_loss: 0.0821\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1137 - val_accuracy: 0.9762 - val_loss: 0.0779\n"
     ]
    }
   ],
   "source": [
    "# Model 4: Dropout\n",
    "with mlflow.start_run(run_name=\"Model 4\"):\n",
    "    log_param(\"hidden_layers\", [256, 128])\n",
    "    log_param(\"learning_rate\", 0.001)\n",
    "    log_param(\"optimizer\", \"Adam\")\n",
    "    log_param(\"regularization\", \"Dropout\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(128, activation='sigmoid'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fca117c-56ea-46e3-b963-0c783ccbd583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8164 - loss: 0.6887 - val_accuracy: 0.9440 - val_loss: 0.1854\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9494 - loss: 0.1692 - val_accuracy: 0.9607 - val_loss: 0.1261\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.1082 - val_accuracy: 0.9691 - val_loss: 0.0988\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9779 - loss: 0.0739 - val_accuracy: 0.9763 - val_loss: 0.0797\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0525 - val_accuracy: 0.9762 - val_loss: 0.0725\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0383 - val_accuracy: 0.9777 - val_loss: 0.0726\n"
     ]
    }
   ],
   "source": [
    "# Model 5: Early Stopping\n",
    "with mlflow.start_run(run_name=\"Model 5\"):\n",
    "    log_param(\"hidden_layers\", [256,128])\n",
    "    log_param(\"learning_rate\", 0.001)\n",
    "    log_param(\"optimizer\", \"Adam\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(256, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(128, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    es = keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0.01, patience=2)\n",
    "    history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[es])\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f26b88d-e994-48a2-b012-a83b0cca5e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1338 - loss: 2.4156 - val_accuracy: 0.3657 - val_loss: 2.5588\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3311 - loss: 1.8843 - val_accuracy: 0.3640 - val_loss: 1.6194\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4770 - loss: 1.5479 - val_accuracy: 0.6407 - val_loss: 1.1260\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.6609 - loss: 1.1361 - val_accuracy: 0.7622 - val_loss: 0.7883\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7187 - loss: 0.9749 - val_accuracy: 0.7684 - val_loss: 0.8418\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7507 - loss: 0.9143 - val_accuracy: 0.7818 - val_loss: 0.8430\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.8871 - val_accuracy: 0.6974 - val_loss: 1.0364\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7472 - loss: 0.9209 - val_accuracy: 0.8143 - val_loss: 0.7482\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7824 - loss: 0.8284 - val_accuracy: 0.8339 - val_loss: 0.7030\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7897 - loss: 0.7986 - val_accuracy: 0.8358 - val_loss: 0.6503\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8256 - loss: 0.6761 - val_accuracy: 0.8490 - val_loss: 0.6062\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8220 - loss: 0.6731 - val_accuracy: 0.8523 - val_loss: 0.6079\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8275 - loss: 0.6613 - val_accuracy: 0.8079 - val_loss: 0.7347\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8234 - loss: 0.6554 - val_accuracy: 0.8639 - val_loss: 0.5163\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8452 - loss: 0.6006 - val_accuracy: 0.8740 - val_loss: 0.5174\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8398 - loss: 0.6016 - val_accuracy: 0.8582 - val_loss: 0.5915\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8499 - loss: 0.5792 - val_accuracy: 0.8530 - val_loss: 0.5461\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8622 - loss: 0.5401 - val_accuracy: 0.8631 - val_loss: 0.5273\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8423 - loss: 0.6064 - val_accuracy: 0.8473 - val_loss: 0.6522\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8581 - loss: 0.5523 - val_accuracy: 0.8621 - val_loss: 0.5016\n"
     ]
    }
   ],
   "source": [
    "# Model 6: Using High LR\n",
    "with mlflow.start_run(run_name=\"Model 6\"):\n",
    "    log_param(\"hidden_layers\", [20,10])\n",
    "    log_param(\"learning_rate\", 10.0)\n",
    "    log_param(\"optimizer\", \"SGD\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(10, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    opt_new = keras.optimizers.SGD(learning_rate=10.0)\n",
    "    model.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d7c3d87-3e84-42f7-9d93-cef47fcc8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1058 - loss: 2.4867 - val_accuracy: 0.1028 - val_loss: 2.4926\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1050 - loss: 2.4859 - val_accuracy: 0.1028 - val_loss: 2.4891\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1043 - loss: 2.4835 - val_accuracy: 0.1028 - val_loss: 2.4857\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1037 - loss: 2.4818 - val_accuracy: 0.1028 - val_loss: 2.4823\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1044 - loss: 2.4743 - val_accuracy: 0.1028 - val_loss: 2.4790\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1029 - loss: 2.4720 - val_accuracy: 0.1028 - val_loss: 2.4758\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1037 - loss: 2.4668 - val_accuracy: 0.1028 - val_loss: 2.4726\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1036 - loss: 2.4630 - val_accuracy: 0.1028 - val_loss: 2.4695\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1036 - loss: 2.4657 - val_accuracy: 0.1028 - val_loss: 2.4665\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1040 - loss: 2.4606 - val_accuracy: 0.1028 - val_loss: 2.4636\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1064 - loss: 2.4555 - val_accuracy: 0.1028 - val_loss: 2.4607\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1052 - loss: 2.4533 - val_accuracy: 0.1028 - val_loss: 2.4578\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1039 - loss: 2.4508 - val_accuracy: 0.1028 - val_loss: 2.4551\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1059 - loss: 2.4485 - val_accuracy: 0.1028 - val_loss: 2.4523\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1050 - loss: 2.4444 - val_accuracy: 0.1028 - val_loss: 2.4497\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1076 - loss: 2.4393 - val_accuracy: 0.1028 - val_loss: 2.4471\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1051 - loss: 2.4413 - val_accuracy: 0.1028 - val_loss: 2.4445\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1047 - loss: 2.4369 - val_accuracy: 0.1028 - val_loss: 2.4420\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1050 - loss: 2.4360 - val_accuracy: 0.1028 - val_loss: 2.4396\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1035 - loss: 2.4328 - val_accuracy: 0.1028 - val_loss: 2.4372\n"
     ]
    }
   ],
   "source": [
    "# Model 7: Using Low LR\n",
    "with mlflow.start_run(run_name=\"Model 7\"):\n",
    "    log_param(\"hidden_layers\", [20,10])\n",
    "    log_param(\"learning_rate\", 0.00001)\n",
    "    log_param(\"optimizer\", \"SGD\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(10, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    opt_new = keras.optimizers.SGD(learning_rate=.00001)\n",
    "    model.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d8e07cf-1082-4ad2-81d9-d62d21d938f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1827 - loss: 2.3045 - val_accuracy: 0.3911 - val_loss: 2.1875\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3953 - loss: 2.1447 - val_accuracy: 0.4525 - val_loss: 1.9531\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4531 - loss: 1.8854 - val_accuracy: 0.5088 - val_loss: 1.6388\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5325 - loss: 1.5760 - val_accuracy: 0.6008 - val_loss: 1.3654\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6228 - loss: 1.3105 - val_accuracy: 0.6835 - val_loss: 1.1413\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6933 - loss: 1.1064 - val_accuracy: 0.7340 - val_loss: 0.9734\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.9586 - val_accuracy: 0.7739 - val_loss: 0.8571\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7741 - loss: 0.8510 - val_accuracy: 0.7993 - val_loss: 0.7727\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8030 - loss: 0.7687 - val_accuracy: 0.8171 - val_loss: 0.7042\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8193 - loss: 0.7021 - val_accuracy: 0.8329 - val_loss: 0.6454\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8327 - loss: 0.6464 - val_accuracy: 0.8464 - val_loss: 0.5940\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8429 - loss: 0.6030 - val_accuracy: 0.8571 - val_loss: 0.5508\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 0.5573 - val_accuracy: 0.8703 - val_loss: 0.5136\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8656 - loss: 0.5231 - val_accuracy: 0.8769 - val_loss: 0.4827\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8740 - loss: 0.4955 - val_accuracy: 0.8823 - val_loss: 0.4572\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8804 - loss: 0.4685 - val_accuracy: 0.8888 - val_loss: 0.4349\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8860 - loss: 0.4422 - val_accuracy: 0.8915 - val_loss: 0.4159\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 0.4246 - val_accuracy: 0.8946 - val_loss: 0.4001\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 0.4046 - val_accuracy: 0.8983 - val_loss: 0.3864\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3953 - val_accuracy: 0.9011 - val_loss: 0.3741\n"
     ]
    }
   ],
   "source": [
    "# Model 8: Using Optimal LR\n",
    "with mlflow.start_run(run_name=\"Model 8\"):\n",
    "    log_param(\"hidden_layers\", [20,10])\n",
    "    log_param(\"learning_rate\", 0.01)\n",
    "    log_param(\"optimizer\", \"SGD\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(10, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    opt_new = keras.optimizers.SGD(learning_rate=.01)\n",
    "    model.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a338148f-bedc-4c91-82ab-8d8cdb209213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.2643 - loss: 2.2269 - val_accuracy: 0.5561 - val_loss: 1.8228\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 1.6673 - val_accuracy: 0.7200 - val_loss: 1.2275\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 1.1398 - val_accuracy: 0.8072 - val_loss: 0.8903\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8121 - loss: 0.8448 - val_accuracy: 0.8471 - val_loss: 0.6960\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8447 - loss: 0.6757 - val_accuracy: 0.8647 - val_loss: 0.5790\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8668 - loss: 0.5626 - val_accuracy: 0.8768 - val_loss: 0.5049\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8769 - loss: 0.4973 - val_accuracy: 0.8839 - val_loss: 0.4540\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8866 - loss: 0.4478 - val_accuracy: 0.8892 - val_loss: 0.4215\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.4116 - val_accuracy: 0.8966 - val_loss: 0.3916\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8973 - loss: 0.3906 - val_accuracy: 0.9012 - val_loss: 0.3687\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9005 - loss: 0.3720 - val_accuracy: 0.9049 - val_loss: 0.3508\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3453 - val_accuracy: 0.9089 - val_loss: 0.3353\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.3371 - val_accuracy: 0.9121 - val_loss: 0.3222\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.3241 - val_accuracy: 0.9151 - val_loss: 0.3113\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.3088 - val_accuracy: 0.9173 - val_loss: 0.3014\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2969 - val_accuracy: 0.9228 - val_loss: 0.2906\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2918 - val_accuracy: 0.9221 - val_loss: 0.2829\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.2761 - val_accuracy: 0.9247 - val_loss: 0.2756\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9272 - loss: 0.2693 - val_accuracy: 0.9274 - val_loss: 0.2685\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9295 - loss: 0.2595 - val_accuracy: 0.9299 - val_loss: 0.2623\n"
     ]
    }
   ],
   "source": [
    "# Model 9: LR with Momentum\n",
    "with mlflow.start_run(run_name=\"Model 9\"):\n",
    "    log_param(\"hidden_layers\", [20,10])\n",
    "    log_param(\"learning_rate\", 0.01)\n",
    "    log_param(\"optimizer\", \"SGD with Momentum\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 32)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(10, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    opt_new = keras.optimizers.SGD(learning_rate=.01, momentum=0.5)\n",
    "    model.compile(optimizer=opt_new, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, epochs=20, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d95b4d8d-0bdb-4459-92df-093144c9b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.1926 - loss: 2.2673 - val_accuracy: 0.4629 - val_loss: 1.9775\n",
      "Epoch 2/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4970 - loss: 1.9110 - val_accuracy: 0.6240 - val_loss: 1.6955\n",
      "Epoch 3/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6553 - loss: 1.6315 - val_accuracy: 0.7372 - val_loss: 1.4284\n",
      "Epoch 4/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7356 - loss: 1.3767 - val_accuracy: 0.7766 - val_loss: 1.1920\n",
      "Epoch 5/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 1.1520 - val_accuracy: 0.8184 - val_loss: 0.9992\n",
      "Epoch 6/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8133 - loss: 0.9648 - val_accuracy: 0.8458 - val_loss: 0.8376\n",
      "Epoch 7/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8407 - loss: 0.8125 - val_accuracy: 0.8716 - val_loss: 0.7097\n",
      "Epoch 8/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8655 - loss: 0.6931 - val_accuracy: 0.8836 - val_loss: 0.6079\n",
      "Epoch 9/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8814 - loss: 0.5930 - val_accuracy: 0.8931 - val_loss: 0.5287\n",
      "Epoch 10/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.5177 - val_accuracy: 0.8986 - val_loss: 0.4681\n"
     ]
    }
   ],
   "source": [
    "# Model 10: Mini-batch SGD\n",
    "with mlflow.start_run(run_name=\"Model 10\"):\n",
    "    log_param(\"hidden_layers\", [20,10])\n",
    "    log_param(\"learning_rate\", 0.01)\n",
    "    log_param(\"optimizer\", \"SGD with Momentum\")\n",
    "    log_param(\"regularization\", \"None\")\n",
    "    log_param(\"batch_size\", 512)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(20, activation='sigmoid', input_shape=(784,)),\n",
    "        layers.Dense(10, activation='sigmoid'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    opt_new = keras.optimizers.SGD(learning_rate=.01, momentum=0.5)\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train, batch_size=512, epochs=10, validation_data=(x_test, y_test))\n",
    "    \n",
    "    train_loss = history.history['loss'][-1]\n",
    "    train_accuracy = history.history['accuracy'][-1]\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "\n",
    "    log_metric('train_loss', train_loss)\n",
    "    log_metric('train_accuracy', train_accuracy)\n",
    "    log_metric('val_loss', val_loss)\n",
    "    log_metric('val_accuracy', val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5991d5c-7d7a-49bb-ab44-bfa57c381b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "216d38cc-eb42-4add-9a68-b57a38171f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model variants\n",
    "models = [\n",
    "    {\"name\": \"Model 1\", \"hidden_layers\": [20, 20], \"learning_rate\": 0.01, \"optimizer\": \"Adam\", \"regularization\": None, \"batch_size\": 32},\n",
    "    {\"name\": \"Model 2\", \"hidden_layers\": [256, 128], \"learning_rate\": 0.01, \"optimizer\": \"SGD\", \"regularization\": None, \"batch_size\": 32},\n",
    "    {\"name\": \"Model 3\", \"hidden_layers\": [256, 128], \"learning_rate\": 0.01, \"optimizer\": \"Adam\", \"regularization\": \"L2\", \"batch_size\": 32},\n",
    "    {\"name\": \"Model 4\", \"hidden_layers\": [256, 128], \"learning_rate\": 0.01, \"optimizer\": \"Adam\", \"regularization\": None, \"batch_size\": 32, \"dropout\": 0.7},\n",
    "    {\"name\": \"Model 5\", \"hidden_layers\": [256, 128], \"learning_rate\": 0.01, \"optimizer\": \"SGD\", \"regularization\": None, \"batch_size\": 32, \"early_stopping\": True},\n",
    "    {\"name\": \"Model 6\", \"hidden_layers\": [20, 20], \"learning_rate\": 10.0, \"optimizer\": \"Adam\", \"regularization\": None, \"batch_size\": 32},\n",
    "    {\"name\": \"Model 7\", \"hidden_layers\": [20, 20], \"learning_rate\": 0.00001, \"optimizer\": \"SGD\", \"regularization\": None, \"batch_size\": 32},\n",
    "    {\"name\": \"Model 8\", \"hidden_layers\": [20, 20], \"learning_rate\": 0.01, \"optimizer\": \"SGD\", \"regularization\": None, \"batch_size\": 32},\n",
    "    {\"name\": \"Model 9\", \"hidden_layers\": [20, 20], \"learning_rate\": 0.01, \"optimizer\": \"SGD\", \"regularization\": None, \"batch_size\": 32, \"momentum\": 0.5},\n",
    "    {\"name\": \"Model 10\", \"hidden_layers\": [20, 20], \"learning_rate\": 0.01, \"optimizer\": \"Adam\", \"regularization\": None, \"batch_size\": 512}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "371441f5-98b9-46eb-9267-0b9b5c1df98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Model 1\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8091 - loss: 0.6637 - val_accuracy: 0.9308 - val_loss: 0.2308\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.2152 - val_accuracy: 0.9342 - val_loss: 0.2182\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.1919 - val_accuracy: 0.9404 - val_loss: 0.2080\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9478 - loss: 0.1767 - val_accuracy: 0.9389 - val_loss: 0.2107\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9503 - loss: 0.1672 - val_accuracy: 0.9427 - val_loss: 0.2023\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9522 - loss: 0.1603 - val_accuracy: 0.9410 - val_loss: 0.2063\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.1535 - val_accuracy: 0.9416 - val_loss: 0.2063\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.1462 - val_accuracy: 0.9472 - val_loss: 0.1913\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9569 - loss: 0.1499 - val_accuracy: 0.9466 - val_loss: 0.1989\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9579 - loss: 0.1402 - val_accuracy: 0.9443 - val_loss: 0.1883\n",
      "Running Model 2\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.2509 - loss: 2.2496 - val_accuracy: 0.6164 - val_loss: 1.9263\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6409 - loss: 1.7298 - val_accuracy: 0.7683 - val_loss: 1.1205\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 1.0253 - val_accuracy: 0.8193 - val_loss: 0.7440\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.7118 - val_accuracy: 0.8543 - val_loss: 0.5771\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8556 - loss: 0.5683 - val_accuracy: 0.8747 - val_loss: 0.4862\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8742 - loss: 0.4873 - val_accuracy: 0.8869 - val_loss: 0.4325\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.4324 - val_accuracy: 0.8931 - val_loss: 0.3965\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.4058 - val_accuracy: 0.8971 - val_loss: 0.3730\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8963 - loss: 0.3796 - val_accuracy: 0.9003 - val_loss: 0.3573\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.3657 - val_accuracy: 0.9039 - val_loss: 0.3425\n",
      "Running Model 3\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.3846 - val_accuracy: 0.9632 - val_loss: 0.1197\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9625 - loss: 0.1211 - val_accuracy: 0.9578 - val_loss: 0.1437\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9703 - loss: 0.0967 - val_accuracy: 0.9661 - val_loss: 0.1091\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.0909 - val_accuracy: 0.9716 - val_loss: 0.0985\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9735 - loss: 0.0843 - val_accuracy: 0.9676 - val_loss: 0.1028\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9760 - loss: 0.0814 - val_accuracy: 0.9710 - val_loss: 0.1087\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9758 - loss: 0.0799 - val_accuracy: 0.9650 - val_loss: 0.1290\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9771 - loss: 0.0743 - val_accuracy: 0.9691 - val_loss: 0.1029\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9779 - loss: 0.0688 - val_accuracy: 0.9680 - val_loss: 0.1134\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0685 - val_accuracy: 0.9673 - val_loss: 0.1070\n",
      "Running Model 4\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8821 - loss: 0.3829 - val_accuracy: 0.9567 - val_loss: 0.1419\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9641 - loss: 0.1164 - val_accuracy: 0.9650 - val_loss: 0.1156\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9676 - loss: 0.1044 - val_accuracy: 0.9659 - val_loss: 0.1126\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0894 - val_accuracy: 0.9650 - val_loss: 0.1180\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9729 - loss: 0.0869 - val_accuracy: 0.9703 - val_loss: 0.1073\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9745 - loss: 0.0829 - val_accuracy: 0.9643 - val_loss: 0.1272\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9748 - loss: 0.0825 - val_accuracy: 0.9663 - val_loss: 0.1077\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9758 - loss: 0.0760 - val_accuracy: 0.9663 - val_loss: 0.1175\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9787 - loss: 0.0698 - val_accuracy: 0.9653 - val_loss: 0.1193\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9777 - loss: 0.0687 - val_accuracy: 0.9685 - val_loss: 0.1187\n",
      "Running Model 5\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.2695 - loss: 2.2424 - val_accuracy: 0.6265 - val_loss: 1.8997\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6382 - loss: 1.7024 - val_accuracy: 0.7494 - val_loss: 1.0981\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7639 - loss: 0.9999 - val_accuracy: 0.8223 - val_loss: 0.7363\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8255 - loss: 0.6985 - val_accuracy: 0.8486 - val_loss: 0.5760\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.8530 - loss: 0.5625 - val_accuracy: 0.8704 - val_loss: 0.4877\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.4881 - val_accuracy: 0.8826 - val_loss: 0.4353\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.4378 - val_accuracy: 0.8918 - val_loss: 0.3990\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8868 - loss: 0.4081 - val_accuracy: 0.8941 - val_loss: 0.3752\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.3922 - val_accuracy: 0.9002 - val_loss: 0.3569\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.3661 - val_accuracy: 0.9010 - val_loss: 0.3435\n",
      "Running Model 6\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1020 - loss: 60.6894 - val_accuracy: 0.0974 - val_loss: 61.4951\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1009 - loss: 54.4336 - val_accuracy: 0.1009 - val_loss: 48.4373\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0991 - loss: 54.8733 - val_accuracy: 0.1010 - val_loss: 64.9210\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0973 - loss: 59.4842 - val_accuracy: 0.1010 - val_loss: 71.0272\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0994 - loss: 55.2473 - val_accuracy: 0.0980 - val_loss: 31.9694\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1016 - loss: 51.8581 - val_accuracy: 0.1135 - val_loss: 37.9627\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1015 - loss: 54.1449 - val_accuracy: 0.1135 - val_loss: 36.0914\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1026 - loss: 54.6843 - val_accuracy: 0.1028 - val_loss: 29.0117\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0989 - loss: 54.5940 - val_accuracy: 0.1009 - val_loss: 49.2733\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.0975 - loss: 57.7062 - val_accuracy: 0.0974 - val_loss: 64.7309\n",
      "Running Model 7\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1057 - loss: 2.3777 - val_accuracy: 0.1049 - val_loss: 2.3788\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1065 - loss: 2.3753 - val_accuracy: 0.1054 - val_loss: 2.3768\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1076 - loss: 2.3700 - val_accuracy: 0.1056 - val_loss: 2.3748\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1059 - loss: 2.3732 - val_accuracy: 0.1058 - val_loss: 2.3728\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1084 - loss: 2.3662 - val_accuracy: 0.1065 - val_loss: 2.3709\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1064 - loss: 2.3646 - val_accuracy: 0.1062 - val_loss: 2.3690\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.1069 - loss: 2.3647 - val_accuracy: 0.1071 - val_loss: 2.3672\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1073 - loss: 2.3625 - val_accuracy: 0.1061 - val_loss: 2.3655\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1060 - loss: 2.3615 - val_accuracy: 0.1061 - val_loss: 2.3638\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.1091 - loss: 2.3574 - val_accuracy: 0.1051 - val_loss: 2.3621\n",
      "Running Model 8\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1685 - loss: 2.3016 - val_accuracy: 0.3550 - val_loss: 2.1881\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.3778 - loss: 2.1333 - val_accuracy: 0.4642 - val_loss: 1.9044\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.5039 - loss: 1.8152 - val_accuracy: 0.6159 - val_loss: 1.4970\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6526 - loss: 1.4067 - val_accuracy: 0.7292 - val_loss: 1.1288\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 1.0738 - val_accuracy: 0.7867 - val_loss: 0.8997\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7924 - loss: 0.8698 - val_accuracy: 0.8141 - val_loss: 0.7571\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8190 - loss: 0.7416 - val_accuracy: 0.8307 - val_loss: 0.6634\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8350 - loss: 0.6582 - val_accuracy: 0.8454 - val_loss: 0.5975\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.5925 - val_accuracy: 0.8553 - val_loss: 0.5479\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8555 - loss: 0.5574 - val_accuracy: 0.8652 - val_loss: 0.5094\n",
      "Running Model 9\n",
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.1647 - loss: 2.3190 - val_accuracy: 0.3617 - val_loss: 2.1827\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.4736 - loss: 2.1277 - val_accuracy: 0.5838 - val_loss: 1.8788\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6257 - loss: 1.7786 - val_accuracy: 0.6944 - val_loss: 1.4480\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 1.3642 - val_accuracy: 0.7779 - val_loss: 1.0995\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7809 - loss: 1.0462 - val_accuracy: 0.8152 - val_loss: 0.8647\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8160 - loss: 0.8352 - val_accuracy: 0.8389 - val_loss: 0.7161\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8388 - loss: 0.7030 - val_accuracy: 0.8550 - val_loss: 0.6181\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.6124 - val_accuracy: 0.8660 - val_loss: 0.5510\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 0.5499 - val_accuracy: 0.8749 - val_loss: 0.5011\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8739 - loss: 0.5034 - val_accuracy: 0.8830 - val_loss: 0.4629\n",
      "Running Model 10\n",
      "Epoch 1/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.5693 - loss: 1.5492 - val_accuracy: 0.8960 - val_loss: 0.4241\n",
      "Epoch 2/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.3622 - val_accuracy: 0.9292 - val_loss: 0.2699\n",
      "Epoch 3/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9322 - loss: 0.2477 - val_accuracy: 0.9366 - val_loss: 0.2285\n",
      "Epoch 4/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9416 - loss: 0.2067 - val_accuracy: 0.9359 - val_loss: 0.2201\n",
      "Epoch 5/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9492 - loss: 0.1783 - val_accuracy: 0.9444 - val_loss: 0.2015\n",
      "Epoch 6/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1646 - val_accuracy: 0.9417 - val_loss: 0.2000\n",
      "Epoch 7/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9566 - loss: 0.1510 - val_accuracy: 0.9478 - val_loss: 0.1857\n",
      "Epoch 8/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9565 - loss: 0.1457 - val_accuracy: 0.9481 - val_loss: 0.1834\n",
      "Epoch 9/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9613 - loss: 0.1318 - val_accuracy: 0.9466 - val_loss: 0.1859\n",
      "Epoch 10/10\n",
      "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9604 - loss: 0.1315 - val_accuracy: 0.9487 - val_loss: 0.1818\n"
     ]
    }
   ],
   "source": [
    "# Create a nested run for each model variant\n",
    "with mlflow.start_run(run_name=\"Superset MNIST\") as parent_run:\n",
    "    for model_config in models:\n",
    "        run_name = model_config[\"name\"]\n",
    "        print(f\"Running {run_name}\") \n",
    "        with mlflow.start_run(run_name=run_name, nested=True) as child_run:\n",
    "            # Create model\n",
    "            model = Sequential()\n",
    "            for i, units in enumerate(model_config[\"hidden_layers\"]):\n",
    "                if i == 0:\n",
    "                    model.add(Dense(units, activation='sigmoid', input_shape=(784,)))\n",
    "                else:\n",
    "                    model.add(Dense(units, activation='sigmoid'))\n",
    "            model.add(Dense(10, activation='softmax'))\n",
    "            \n",
    "            # Compile model\n",
    "            optimizer = keras.optimizers.SGD(learning_rate=model_config[\"learning_rate\"])\n",
    "            if model_config[\"optimizer\"] == \"SGD\":\n",
    "                optimizer = keras.optimizers.SGD(learning_rate=model_config[\"learning_rate\"])\n",
    "            elif model_config[\"optimizer\"] == \"Adam\":\n",
    "                optimizer = keras.optimizers.Adam(learning_rate=model_config[\"learning_rate\"])\n",
    "            model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "            \n",
    "            # Log parameters\n",
    "            mlflow.log_param(\"hidden_layers\", model_config[\"hidden_layers\"])\n",
    "            mlflow.log_param(\"learning_rate\", model_config[\"learning_rate\"])\n",
    "            mlflow.log_param(\"optimizer\", model_config[\"optimizer\"])\n",
    "            mlflow.log_param(\"regularization\", model_config[\"regularization\"])\n",
    "            mlflow.log_param(\"batch_size\", model_config[\"batch_size\"])\n",
    "            \n",
    "            # Train model\n",
    "            history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=model_config[\"batch_size\"])\n",
    "            \n",
    "            # Log metrics\n",
    "            mlflow.log_metric(\"train_loss\", history.history[\"loss\"][-1])\n",
    "            mlflow.log_metric(\"train_accuracy\", history.history[\"accuracy\"][-1])\n",
    "            mlflow.log_metric(\"val_loss\", history.history[\"val_loss\"][-1])\n",
    "            mlflow.log_metric(\"val_accuracy\", history.history[\"val_accuracy\"][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
